\chapter{Implementation}
\label{chapter:implementation}

\section{Ledger}

The only component in the system we have implemented that is not distributed is the ledger.
The ledger acts as the catalog for the files stored in the network,
as well as the reputation of the peers.
Ideally the ledger should be distributed in order for the system to be fully decentralized.
An example of a distributed ledger technology is any blockchain.
Initially we considered using one of Near, Solana, or Substrate \cite{near, solana, substrate}.
These are all blockchains implemented in Rust, which is the language we are using for the implementation.
This would have allowed us to easily integrate the ledger more easily with the rest of the system.
However, we decided against using a blockchain for the ledger for this implementation
mainly because of the complexity of integrating with a blockchain.
We see this as a future work in order to make the system production ready,
and we will discuss the integration with a blockchain in the \autoref{chapter:future-work}.

\section{Using the immutable database Immudb}
\label{section:using-immudb}

The backbone of the integrity of the system is the immutable database Immudb \cite{immudb}.
An immutable database ensures we can store the metadata necessary to run the system
in a tamper-proof way.
The database acts as a form of catalog for the files stored in the network,
storing the keys and metadata required to perform audits.
Immudb is a lightweight, high-speed immutable database that is designed to be used as a key-value store.
It is based on the Merkle tree data structure, which allows for efficient verification of the integrity of the data.
The database is designed to be tamper-proof, meaning that although the database supports updates and deletes,
the history of the data is always preserved.
If a record is changed or deleted,
the database keeps a record of the change, and the history of the record can be traced back to its creation.
This property is crucial for the reputation system, as it ensures that the reputation scores are not tampered with,
or if they are tampered with the client of the database can detect the tampering.

\subsection{Using Immudb at scale}

One downside of the database is that it is not innately designed to be distributed.
This means that the database is not designed to be run on multiple nodes,
and it does not support replication out of the box.
In a real-world scenario, running the database on a single node is a huge flaw,
as it makes the database a single point of failure.
For the purposes of our experiments, we will run the database on a single node.
However, we will briefly discuss how the database can be made distributed in the future.
The first approach is by distributing the Immudb itself.
We could shard the data and run multiple instances of the database on different peers.
Since the database is immutable, peers can be sure that the data is consistent across all the nodes.
For example, sharding the data could be done by taking the file key, or the hash of the file key as the shard key.
This way it would be easy to locate where the metadata for a given file is stored.
The second approach is to use the storage system itself, completely removing the need for the database.
This would require more work to ensure the system can support the same operations as the database,
but it would simplify the querying, as the metadata would be stored in the same place as the files.

\subsection{Atomic Operations in Immudb}

The second downside of the database is that it does not support complex queries.

For example, we need to atomically update the reputation of a peer after a successful audit.
Since audits may happen in parallel, we need to ensure that the reputation is updated correctly.
This means that we need to read the current reputation of the peer, increment it, and write it back to the database.
This operation needs to be atomic, as we do not want to lose any updates.

\begin{lstlisting}[language=SQL, caption={SQL query to update the reputation of a peer}, label={lst:sql-query}]
BEGIN TRANSACTION;
DECLARE @value INT;
SELECT @value = reputation FROM reputations WHERE peer_id = @peer_id;
UPDATE reputations SET reputation = @value + 1 WHERE peer_id = @peer_id;
COMMIT TRANSACTION;
\end{lstlisting}

The above query would work in a traditional SQL database, but it would not work in Immudb,
because Immudb supports only simple SELECT, INSERT, UPDATE, and DELETE operations.
Luckily it does support transactions, which we can use to ensure that the operation is atomic.

Immudb supports two ways of authentication, both making use of a token.
The first way is to log in as a temporary user, which enables the use of single SQL queries.
For example, after a login, we can execute an INSERT followed by a SELECT followed by another INSERT.
These queries are independent of each other.
If we want to use transactions, we need to log in and establish a session, followed by initiating a transaction.
These two operations return unique tokens that we need to pass as headers with each subsequent request.
Initiating a transaction is the equivalent of the SQL BEGIN TRANSACTION command.
This way, the database knows which session and transaction we are referring to.
The session token is used to authenticate the user,
while the transaction token is used to ensure that the operations are atomic.
After we execute the operations, we need to commit the transaction to make the changes permanent.
Lastly we need to close the session to free up resources.

\subsection{Conflict Resolution}

Immudb does not support conflict resolution out of the box.
Under the hood, immudb uses transactions even in the case of a non-session login.
The delay in the transactions is minimal, but it can affect the queries.
In particular, if two writes happen at the same time (or close to each other),
the database will return an error --- \texttt{ErrTxReadConflict}.
This error stands for "tx read conflict" and it means that the transaction was not successful
because another transaction was committed in the meantime.
It occurs even when the query is not a transaction,
so for example when adding a new file to the database, and we write the contract to the database, it can fail.
Immudb does not provide a way to automatically retry the transaction,
so we had to implement the retry mechanism in the client.
The official documentation acknowledges this issue and mentions that MVCC (Multi-Version Concurrency Control)
is on the roadmap, but not yet implemented, hence such failures are expected and need to be handled by the client.

\subsection{Using Immudb to store the files (rejected idea)}

One way for us to verify that a malicious peer is not modifying/deleting the files is
to store the files in an immutable database (this does nothing against bit rot or hardware failures).
Since it is immutable, it preserves the history of the data, and we can always request to see the history
of the file to verify that it has not been tampered with.
So why do we not run an Immudb instance on each peer and store the files in it?
The reason is that this introduces additional complexity.

While the peer cannot modify the file, without leaving a trace,
it can always wipe the database and recreate it.
This will remove the history and make it seem like no changes were made.
Any data stored on the peer is at risk of being deleted or modified,
and therefore cannot be trusted.
Perhaps we can check the timestamp of the time of storing the file,
but this can be easily modified by the peer if they use a modified Immudb instance.

These and more considerations would need to be made if we were to use this approach.
It enables a different class of attacks for which we would need to augment the system.
In particular, we would need to implement ways to deal with these attacks in the Kademlia layer,
and we would need to implement a new storage interface for Immudb, that Kademlia can use.

While this is not impossible, it is considerably more work than adapting Kademlia to
work with PoR and store files on the disk.

\section{Kademlia}

Kademlia is the distributed hash table (DHT) that we use to store the files in the network.
We are using the implementation from the official Rust libp2p crate \cite{rustlibp2p}.
We have made some extensions to the implementation to support our use cases.
One of these is the local storage, which we will discuss in the following section.
We have also included a direct peer to peer communication channel,
which is referred to as a request-response protocol in the libp2p documentation,
and we use it to perform audits required for the Proof of Retrievability.
This was required since the base implementation of Kademlia is closed for extension,
and we needed a way to communicate with the peers directly.

An important note here is that the Kademlia implementation supports only some basic operations,
some of which differ from the original Kademlia paper.
For example, the storage operation stores the value on the current node,
while the original Kademlia paper stores the value on the closest node to the key.
Therefore, to achieve the original behavior of the Kademlia paper,
we had to implement part of the Kademlia protocol ourselves.
For the PUT operation in particular, we first use GET_CLOSEST_PEERS to find the closest peers to the key,
and then perform the PUT operation on the peers we found.
This was not a huge downside since it allowed us to easily inject the PoR protocol into this operation.
The initialization step of the PoR protocol happens when we store the file for the first time.
We have to create a secret vector that the Keeper where the file will be stored does not know.
So once we find the closest peers to the key, we initialize the PoR secret vector,
and then we store the file on the Keeper,
while simultaneously storing the PoR secret as well as additional metadata in the ledger.

\section{Local Storage}

TODO

\section{Malicious Peer Behaviors}

TODO

\section{Proof of Retrievability}

TODO


\section{Reputation System}
\label{section:reputation-system}

The backbone of the reputation system is the immutable database Immudb \cite{immudb}.
We will consider the database as a single source of truth for the reputation of the peers.

The reputation system is designed to keep track of the behavior of the peers in the network.
When a peer accepts to store a file, it stakes a certain amount of reputation points.
Staking is temporary decrease of reputation points,
which is returned to the peer after the expiry date of the file.
\wtf{TODO: I'm still playing around with this idea, I'm not sure if this is the best way to do it.
Perhaps the staked reputation will be returned gradually with each successful audit.
The whole idea of adding "staking" is to ensure the peer has a big hit in reputation from the beginning.
This way a new peer in the network cannot just accept a lot of files as soon as it joins and then go offline.}
Every time an audit is performed the reputation of the peer on which the audit was performed is adjusted.
If the audit is successful, the reputation of the peer is increased,
and if the audit fails, the reputation of the peer is decreased.
Finally, a peer is awarded reputation points for performing audits.
The increase and decrease numbers are configurable and can be adjusted to fit the network requirements.
We will discuss the different possibilities for adjusting the reputation in the \autoref{chapter:evaluation}
