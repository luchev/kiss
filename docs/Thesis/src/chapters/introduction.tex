\label{chapter:introduction}
\chapter{Introduction}

Cloud storage is a key component of modern computing.
It allows users to store and access their data from anywhere in the world.
A lot of the popular cloud storage providers are centralized, meaning owned and operated by a single entity.
On one hand, this is good for the user because the entity provides a friendly interface and customer support
in exchange for a fee.
On the other hand, the user has to trust the entity to keep their data safe and private and not misuse it.
They also might prefer to pay with their storage or computation power instead of money, or 
they might not want to be locked into a single provider.
Such cases are often when the user is a university or a government.

To address such use cases and the concerns with cloud storage, decentralized storage systems have been proposed.

We will focus on the most popular type of decentralized storage, which is decentralized hash tables (DHT).
They are often used as the basis of NoSQL databases, such as Cassandra \cite{cassandra},
which are used by companies such as Facebook, Twitter, and Netflix, in order to serve millions of users.
While they can be used for centralized storage, they are mostly used as decentralized storage,
therefore they focus on privacy, security, fault tolerance, and resistance to censorship.

The goal of this thesis is to design and implement a secure and fault-tolerant decentralized storage system
that can compete with centralized storage systems.
In particular, we will focus on the integrity of the data stored on the network,
as this is the main problem that is not addressed by existing decentralized storage systems.
In the following sections, we will introduce decentralized networks,
define what security and integrity means, discuss the motivation for this work,
and propose a solution to the integrity problem in modern decentralized networks.
We will then talk about the requirements for the system and how we will evaluate it.

\section{Overview of cloud storage}

Cloud storage provides a way to store and access data over the Internet.
The user does not need to worry about the physical location of the storage, the hardware, the maintenance,
the replication, the backups, etc., as it is abstracted away by the cloud storage provider.
If we want to build a decentralized storage system, we need to provide the same guarantees and features
as centralized storage systems.
For this purpose we will explore the requirements for Amazon's S3,
which is one of the most popular cloud storage providers.

\begin{enumerate}
    \item The system can store from 0 to 5 terabytes of data in a single object.
    \item The system can store an unlimited number of objects.
    \item The system can store an object for an unlimited amount of time.
    \item The cloud provider will not access the data for any purpose, except when required to do so by law.
    \item Files will be stored under keys, which are unique identifiers and
        can be constructed to mimic a hierarchical structure.
    \item The system will provide a simple REST API to store and retrieve the objects.
    \item Files stored by the user can be accessed only by the user, unless the user decides to share the file.
    \item Data is stored encrypted, and the user can provide their own encryption key.
    \item The system can provide 99.999999999\% durability of the data (achieved via verification).
    \item The system can provide 99.99\% availability.
    \item The system can provide 99.99\% of the time the objects will be retrieved in less than 100 milliseconds.
    \item Deletes are guaranteed to be permanent, and no data can be recovered after a deletion.
    \item The system provides different types of replication - region and cross-region.
\end{enumerate}

These features come at a cost, which is usually a fee for the storage and the bandwidth.

If we want to build a decentralized storage system, we need to provide the same guarantees and features.
While we cannot restrict which users can access the data, we can encrypt it,
which will make it unreadable to anyone who does not have the decryption key.
There is one feature that is hard to achieve in a decentralized network - deletion.
Because the data is stored on multiple nodes, and we cannot guarantee that all of them will delete the file,
but since the data is encrypted, it is not readable to anyone who does not have the decryption key.

Most of the features are covered by existing decentralized storage systems, but the one that is not is durability.
Durability or data integrity is the main focus of this thesis.
We will approach the problem by using the same method as centralized storage systems - verification.
Before we discuss the verification method, we will briefly talk about decentralized networks and security,
in order to provide the necessary background for the rest of the thesis.

\wtf{I can move the whole introduction to decentralized networks and security to the Related Work section.
But then the reader will not have the necessary background, and will need to read the Related Work section first.}

\section{Overview of decentralized networks}

Decentralized storage is implemented on top of peer to peer (P2P) networks.
They are a type of network where each node acts as both a client and a server.
This means that each node can request and provide services to other nodes.
There is also no central server, although there may be a central directory to help nodes find each other.

Decentralized networks can be classified into two categories - unstructured and structured.
Structured networks have a predefined topology and are more efficient in terms of routing and resource discovery.
Often used topologies are circular and hypercube.
The most popular structured network is Kademlia \cite{kademlia}, which uses a hypercube topology.
It is also the foundation for most modern decentralized storage systems.

\section{Anonymity}

Security is a major concern in decentralized networks,
as they are open to anyone and there is no central authority to enforce rules.
The definition of security can be different from system to system.
Some systems focus on anonymity of the users and nodes storing the data,
while others discard anonymity in order to track the nodes and the data they store.
Solving anonymity is done by using completely different methods such as
onion routing (used by Tor \cite{tor}) and cover traffic (Tarzan \cite{tarzan}).
We will not focus on anonymity, as it disallows us from tracking the integrity of data stored on the network.

Most decentralized networks focus on efficient routing and resource discovery.
Security is often an afterthought, if it is considered at all.
After multiple networks with $O(\log n)$ query time were proposed \cite{chord, kademlia, pastry},
the focus shifted to security.

\section{Security}

Security is a major concern in decentralized networks because
the network is open to anyone, and there is no central authority to enforce rules,
in contrast to centralized storage systems.
Peers can join and leave the network at any time, and they can lie about their identity and the data they store.
We call such peers malicious.

When we talk about security we assume that the underlying network provides no security guarantees.
Attackers can eavesdrop on the communication between nodes, modify the messages, and even drop them.
They can also spoof IP addresses and there is no authentication of data packets in the underlying network.
This is a reasonable assumption as most decentralized networks are built on top of the Internet,
which is inherently insecure.

S/Kademlia \cite{skademlia} summarizes the main attacks on decentralized networks:
\begin{enumerate}
    \item \textbf{Eclipse attacks} - an attacker isolates a node from the rest of the network.
    \item \textbf{Sybil attacks} - a single entity pretends to be multiple entities.
    \item \textbf{Churn attacks} - an attacker joins and leaves the network repeatedly.
    \item \textbf{Adversarial routing} - an attacker returns adversarial routing information.
    \item \textbf{Denial-of-service attacks} - an attacker floods the network with requests.
    \item \textbf{Storage attacks} - an attacker manipulates the data stored on a node.
\end{enumerate}

Kademlia and S/Kademlia cover most of these attacks and are mostly secure against them.
The one exception is storage attacks.
No decentralized network has a solution for storage attacks.

\subsection{Storage attacks}
\label{section:storage-attacks}

Storage attacks are the main focus of this thesis.
They are mostly ignored by the literature, because decentralized networks are often designed to
drop old files based on some criteria, such as popularity or age.
This is done to save space and to keep the network up to date.
However, if we want durable storage, we need to address these attacks.

Storage attacks can be classified into two categories:
\begin{enumerate}
    \item \textbf{Data availability attacks} - an attacker claims to store data, but does not.
    \item \textbf{Data integrity attacks} - an attacker claims to store data, but stores different data.
\end{enumerate}

Checking if a node stores the data it claims to store can be as simple as asking the node to return the data.
However, this is a very inefficient and bandwidth-consuming method.
Ideally, we would like to reduce the amount of traffic between nodes and still be able to check
if the data is stored correctly.

\section{Requirements for the system}

If we want to design a decentralized storage system that is similar and can compete with centralized systems,
we need to provide the same guarantees and features:
\begin{enumerate}
    \item \textbf{Scalability} - the system should be able to handle many users and data.
    \item \textbf{Performance} - the system should be fast.
    \item \textbf{Resilience} - the system should be able to recover from attacks.
    \item \textbf{Reliability} - the system should be able to recover from failures.
    \item \textbf{Availability} - data stored on the network should be accessible at all times.
    \item \textbf{Integrity} - data stored on the network should not be tampered with.
    \item \textbf{Security} - data stored on the network, and accessing the data should be secure.
\end{enumerate}

\textbf{Scalability} is covered by most networks, regardless of being centralized or decentralized.
Allowing many peers to join the network is a key feature of decentralized networks.
\textbf{Performance} is also covered by most modern networks, as they provide $O(\log n)$ query time.
\textbf{Resilience} is for the most part covered by the security additions to the networks, such as S/Kademlia.
An exception is the storage attacks, which are not addressed.
\textbf{Reliability} is covered by rebalancing the network when a node leaves or joins.
Most networks also provide some form of redundancy, which allows the network to recover from failures.
\textbf{Availability} follows from reliability and resilience.
\textbf{Security} can be solved by using encryption, cover traffic, onion routing, etc.
\textbf{Integrity} is not the focus of existing networks, as discussed in \ref{section:storage-attacks}.

These requirements have some overlap.
In order to achieve resilience, we need to guarantee the integrity of the data.
In order to achieve performance, we need optimized way to check the integrity of the data.
And to achieve availability, we need the above two.

If we want a system to compete with centralized storage systems, we
need to be able to provide guarantees about the data stored on the network.
A lot of the popular centralized storage systems provide data durability and
availability of five (99.999\%) or more nines.

\section{Solving the integrity problem}

To solve the integrity problem, we need to be able to check if the data is stored correctly.
To achieve this we need a verification/auditing mechanism, which is efficient and secure.
We will use a Proof of Retrievability (PoR) scheme, which will allow us to efficiently check the 
integrity of the data stored in the network.
PoR schemes are a type of cryptographic scheme that allows a verifier to check if a node
stores the data it claims to store.
The verifier does not need to download the whole file, but only exchange a few messages, which are much smaller.

Once we have a method to check the integrity of the data, we need someone to perform this check.
We will use the nodes in the network to perform the checks.
It makes sense for honest nodes, which are users of the network, to do audits,
as they have a vested interest in the integrity of the data.
However, we also need to make sure that malicious nodes are also doing audits.

We can achieve this by using rewards and penalties.
We will reward nodes for performing audits and penalize them for not performing audits.
First, let us focus on the penalties.
If a node is found to be storing data incorrectly (by failing an audit), we will penalize the node.
If a node is found to not be performing audits, we will penalize it.

The only way to penalize a node is to remove it from the network.
It would be better if we could have lighter penalties.
Here we are proposing a reputation system based on a ledger store, e.g., a blockchain.
We will use a blockchain to store the reputation of the nodes.
This will allow us to have a light penalty system, as we can downgrade the reputation of the node
instead of removing it from the network.
Using a ledger store allows us to have a transparent and immutable record of the reputation of the nodes.

Using a reputation system will also allow us to reward nodes for performing audits.
Successfully storing a file and passing audits will increase the reputation of the node.
Successfully performing audits will also increase the reputation of the node.
Failing to store a file or failing to perform an audit will decrease the reputation of the node.
In the \ref{section:evaluation} we will discuss how very high or low reputation nodes will be treated.

We know how to perform audits, but we also need to know how to make sure none of the
audits are faked.
To solve this, we would require the nodes performing an audit to record the results of the audit and keep
it in a ledger store.
When a node is suspicious of the correctness of the audit, it can check the ledger store to see if the audit
was performed correctly.
This could also be used to check if the audits are being performed at all.

\label{section:evaluation}
\section{Evaluation and testing}

Of the requirements, Scalability, Performance, Resilience, Reliability, Availability, and Security
are covered by other works.
We need to evaluate the Integrity requirement, which will be done by evaluating the verification/auditing mechanism,
the penalties and rewards for the nodes, and the reputation system.
Implementing the validation system could make the performance degrade, so we have to evaluate
if any of the requirements are affected by the validation system, and if so, how much.
We will discuss the details and the results of the evaluation in \ref{chapter:evaluation}.
